{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67844270",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import torch\n",
    "#from mxnet import autograd, np, npx\n",
    "#from d2l import mxnet as d2l\n",
    "import numpy as np\n",
    "#npx.set_np()\n",
    "def synthetic_data(w, b, num_examples):  #@save\n",
    "    \"\"\"生成y=Xw+b+噪声\"\"\"\n",
    "    X = torch.normal(0, 1, (num_examples, len(w)))\n",
    "    y = torch.matmul(X, w) + b\n",
    "    y += torch.normal(0, 0.01, y.shape)\n",
    "    return X, y.reshape((-1, 1))\n",
    "\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = torch.tensor(4.2)\n",
    "features, labels = synthetic_data(true_w, true_b, 1000)\n",
    "def data_iter(batch_size, features, labels):#feature是x, lable是y,一次取10个\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    # 这些样本是随机读取的，没有特定的顺序\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        batch_indices = np.array(\n",
    "            indices[i: min(i + batch_size, num_examples)])\n",
    "        yield features[batch_indices], labels[batch_indices]\n",
    "batch_size = 10\n",
    "\n",
    "for X, y in data_iter(batch_size, features, labels):\n",
    "    print(X, '\\n', y)\n",
    "w = torch.normal(0, 0.01, (2, 1),requires_grad=True)\n",
    "b = torch.zeros(1,requires_grad=True)\n",
    "def linreg(X, w, b): #@save\n",
    "    \"\"\"线性回归模型\"\"\"\n",
    "    return torch.matmul(X, w) + b\n",
    "def squared_loss(y_hat, y): #@save\n",
    "    \"\"\"均方损失\"\"\"\n",
    "    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2\n",
    "def sgd(params, lr, batch_size): #@save\n",
    "    \"\"\"小批量随机梯度下降\"\"\"\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr * param.grad \n",
    "            param.grad.zero_()\n",
    "            \n",
    "lr = 0.03\n",
    "num_epochs = 3\n",
    "net = linreg\n",
    "loss = squared_loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter(batch_size, features, labels):\n",
    "        l = loss(net(X, w, b), y) # X和y的小批量损失\n",
    "        # 因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起，\n",
    "        # 并以此计算关于[w,b]的梯度\n",
    "        l.requires_grad_=True\n",
    "        l.mean().backward()\n",
    "        sgd([w, b], lr, batch_size) # 使用参数的梯度更新参数\n",
    "    with torch.no_grad():\n",
    "        train_l = loss(net(features, w, b), labels)\n",
    "        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')\n",
    "print(w,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b774231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch \n",
    "epochs=3\n",
    "w_true=torch.tensor([-2500,2.9])\n",
    "b_true=torch.tensor(1.75)\n",
    "x=torch.normal(4,3,(1000,2))\n",
    "def line_reg(w,b,x):\n",
    "    y=torch.matmul(x,w.reshape(-1,1))+b\n",
    "    y+=torch.normal(0,0.01,y.shape)\n",
    "    return y\n",
    "y=line_reg(w_true,b_true,x)\n",
    "w=torch.zeros_like(w_true,requires_grad=True)\n",
    "b=torch.zeros_like(b_true,requires_grad=True)\n",
    "batch_size=10\n",
    "epochs=101\n",
    "learnrate=0.003\n",
    "def data_iterature(batch_size,input_x,input_y):#每次随机抽10个\n",
    "    num_examples = len(input_x)\n",
    "    indices = list(range(num_examples))\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        batch_indices = indices[i:i + batch_size]  # 直接按 batch_size 切分\n",
    "        yield input_x[batch_indices], input_y[batch_indices]  # 使用 yield 生成批次\n",
    "print(data_iterature(batch_size,x,y))\n",
    "def sgd(params,lr):\n",
    "    with torch.no_grad():#参数更新时使用，以免引入不必要的计算\n",
    "       for param in params:\n",
    "            param -= lr * param.grad\n",
    "            param.grad.zero_()\n",
    "def loss(y1,y2):\n",
    "    return (y1-y2)**2\n",
    "for epoch in range(epochs):\n",
    "    for input_x,input_y in data_iterature(batch_size,x,y):\n",
    "        y_pred=torch.matmul(input_x,w.reshape(-1,1))+b\n",
    "        l=loss(y_pred,input_y).mean()\n",
    "        print(l)\n",
    "        l.backward()\n",
    "        sgd([w,b],learnrate)\n",
    "    with torch.no_grad():\n",
    "            train_l = loss(torch.matmul(w,x.reshape(2,1000))+b, y)\n",
    "            print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')\n",
    "print([w,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8141bdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "#from torch.utils import data\n",
    "true_w = torch.tensor([2, -3.4])\n",
    "true_b = 4.2\n",
    "features=torch.normal(0,1,(1000,2))\n",
    "labels=torch.matmul(features,true_w.reshape(2,1))+true_b\n",
    "#print(labels)\n",
    "# labels=labels.squeeze()\n",
    "# print(labels)\n",
    "def load_array(data_arrays, batch_size): #@save\n",
    "    \"\"\"构造一个PyTorch数据迭代器\"\"\"\n",
    "    dataset = torch.utils.data.TensorDataset(*data_arrays)\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size)\n",
    "batch_size = 10\n",
    "data_iter = load_array((features, labels), batch_size)\n",
    "iterator=iter(data_iter)\n",
    "# for batch in data_iter:\n",
    "#     print(batch)\n",
    "net=torch.nn.Sequential(torch.nn.Linear(2,1))\n",
    "net[0].weight.data.normal_(0,0.1)\n",
    "net[0].bias.data.fill_(0)\n",
    "loss=nn.MSELoss()\n",
    "trainer=torch.optim.SGD(net.parameters(),lr=0.01)\n",
    "epochs=100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for x,y in data_iter:\n",
    "        trainer.zero_grad()\n",
    "        l=loss(net(x),y)\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "    with torch.no_grad():\n",
    "        l=loss(net(features),labels)\n",
    "        print(f'epoch {epoch + 1}, loss {l:f}')\n",
    "print(net[0].weight,net[0].bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a305115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils import data\n",
    "from torch import nn\n",
    "true_w=torch.tensor([3,-5,1.6])\n",
    "true_b=torch.tensor(-4.1)\n",
    "features=torch.normal(0,5,(1000,3))\n",
    "labels=torch.matmul(features,true_w)+true_b\n",
    "# features=(features_origin-features_origin.mean())/features_origin.std()\n",
    "# labels=(labels_origin-labels_origin.mean())/labels_origin.std()\n",
    "print(features[0])\n",
    "print(labels[0])\n",
    "def data_iter(batch_size,features,labels):\n",
    "    iter=data.TensorDataset(*(features,labels))\n",
    "    print(data.DataLoader(iter,batch_size))\n",
    "    return data.DataLoader(iter,batch_size)\n",
    "epoches=1000\n",
    "loss=nn.SmoothL1Loss(beta=0.5)\n",
    "batch_size=50\n",
    "models=torch.nn.Sequential(torch.nn.Linear(3,1))\n",
    "models[0].weight.data.normal_(0,3)\n",
    "models[0].bias.data=torch.tensor(1.0)\n",
    "trainer=torch.optim.SGD(models.parameters(),lr=0.01)\n",
    "for epoch in range(epoches):\n",
    "    for x,y in data_iter(batch_size,features,labels):\n",
    "        trainer.zero_grad()\n",
    "        l=loss(y,models(x).squeeze())\n",
    "        l.backward()\n",
    "        print(models[0].weight.grad,\"权重\\n\")\n",
    "        print(models[0].bias.grad,\"偏置\\n\")\n",
    "        trainer.step()\n",
    "    with torch.no_grad():\n",
    "        l=loss(labels,models(features).squeeze())\n",
    "        print(f'epoch{epoch+1},{l:f}loss')\n",
    "print(models[0].weight,models[0].bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb134084",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.ticker import FuncFormatter, MultipleLocator\n",
    "import numpy as np\n",
    "import torch\n",
    "# def pi_half_formatter(val, pos):\n",
    "#     # 计算 π 的半整数倍系数\n",
    "#     coeff = val / (np.pi / 2)\n",
    "#     coeff = int(round(coeff))\n",
    "#     sign = '-' if coeff < 0 else ''  # 手动处理符号\n",
    "#     # 如果系数是整数或者非常接近整数（考虑浮点数精度），则显示该整数倍的 π/2\n",
    "#     if coeff % 2 == 0:\n",
    " \n",
    "#         if coeff==0:\n",
    "#             return '0'\n",
    "#         elif abs(coeff) == 2:\n",
    "#             return fr'${sign}\\pi$'          # 显示 π 而不是 1π\n",
    "#         else:\n",
    "#             return fr'${sign}{abs(coeff)//2}\\pi$' # 2π, 3π...\n",
    "#     else:\n",
    "#         if coeff == 1:\n",
    "#             return fr'${sign}\\frac{{\\pi}}{{2}}$'  # π/2\n",
    "#         else:\n",
    "#             return fr'${sign}\\frac{{{abs(coeff)}\\pi}}{{2}}$'  # 3\n",
    "def pi_half_formatter(val, pos):\n",
    "    \"\"\" 将数值格式化为 π/2 的倍数 \"\"\"\n",
    "    unit = np.pi / 2\n",
    "    coeff = val / unit  # 计算系数\n",
    "    \n",
    "    # 浮点精度处理：判断是否接近整数\n",
    "    if not np.isclose(coeff, round(coeff), atol=1e-9):\n",
    "        return ''  # 非整数倍时返回空字符串\n",
    "    \n",
    "    coeff = int(round(coeff))\n",
    "    sign = '-' if coeff < 0 else ''  # 手动处理符号\n",
    "    abs_coeff = abs(coeff)\n",
    "    \n",
    "    # 生成LaTeX标签\n",
    "    if abs_coeff == 0:\n",
    "        return r'$0$'\n",
    "    elif abs_coeff % 2 == 0:\n",
    "        multiple = abs_coeff // 2\n",
    "        if multiple == 1:\n",
    "            return fr'${sign}\\pi$'\n",
    "        else:\n",
    "            return fr'${sign}{multiple}\\pi$'\n",
    "    else:\n",
    "        if abs_coeff == 1:\n",
    "            return fr'${sign}\\frac{{\\pi}}{{2}}$'\n",
    "        else:\n",
    "            return fr'${sign}\\frac{{{abs_coeff}\\pi}}{{2}}$'\n",
    "f,ax=plt.subplots(1)\n",
    "x = np.linspace(-3*np.pi, 3*np.pi, 100)\n",
    "x1= torch.tensor(x, requires_grad=True)\n",
    "y1= torch.sin(x1)\n",
    "y1.backward(torch.ones_like(x1))\n",
    "print(x1.grad.type())\n",
    "ax.plot(x,np.sin(x),label='sin(x)')\n",
    "ax.plot(x,x1.grad,label=\"gradient of sin(x)\")\n",
    "ax.legend(loc='lower right', shadow=False)\n",
    "\n",
    "ax.xaxis.set_major_formatter(FuncFormatter(pi_half_formatter))\n",
    "ax.xaxis.set_major_locator(MultipleLocator(base=np.pi/2))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07673e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "# 通过ToTensor实例将图像数据从PIL类型变换成32位浮点数格式，\n",
    "# 并除以255使得所有像素的数值均在0～1之间\n",
    "trans = transforms.ToTensor()\n",
    "mnist_train = torchvision.datasets.FashionMNIST(\n",
    "    root=r\"C:\\Users\\Lenovo\\Desktop\\visiondata\", train=True, transform=trans, download=True)\n",
    "mnist_test = torchvision.datasets.FashionMNIST(\n",
    "    root=r\"C:\\Users\\Lenovo\\Desktop\\visiondata\", train=False, transform=trans, download=True)\n",
    "len(mnist_train), len(mnist_test)\n",
    "type(mnist_train[1])#60000行，2列，第一列是图像ternsor 1,28,28，第二列是label(int)\n",
    "def get_fashion_mnist_labels(labels):  #@save\n",
    "    \"\"\"返回Fashion-MNIST数据集的文本标签\"\"\"\n",
    "    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "    return [text_labels[int(i)] for i in labels]\n",
    "def show_images(imgs, num_rows, num_cols, titles=None, scale=1):  #@save\n",
    "    \"\"\"绘制图像列表\"\"\"\n",
    "    figsize = (num_cols * scale, num_rows * scale)\n",
    "    _, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    for i, (ax, img) in enumerate(zip(axes, imgs)):\n",
    "        if torch.is_tensor(img):\n",
    "            # 图片张量\n",
    "            #print(img.squeeze().numpy())\n",
    "            ax.imshow(img.squeeze().numpy())\n",
    "        else:\n",
    "            # PIL图片\n",
    "            ax.imshow(img)\n",
    "        \n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "        if titles:\n",
    "            ax.set_title(titles[i])\n",
    "        #ax.axis('off')\n",
    "    return axes\n",
    "# X, y = next(iter(data.DataLoader(mnist_train, batch_size=18)))\n",
    "# show_images(X.reshape(18, 28, 28), 2, 9, titles=get_fashion_mnist_labels(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beeb46df",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter = data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                             num_workers=12)\n",
    "def load_data_fashion_mnist(batch_size, resize=None):  #@save\n",
    "    \"\"\"下载Fashion-MNIST数据集，然后将其加载到内存中\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(\n",
    "        root=r\"C:\\Users\\Lenovo\\Desktop\\visiondata\", train=True, transform=trans, download=True)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(\n",
    "        root=r\"C:\\Users\\Lenovo\\Desktop\\visiondata\", train=False, transform=trans, download=True)\n",
    "    return (data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                            num_workers=12),\n",
    "            data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
    "                            num_workers=12))\n",
    "train_iter, test_iter = load_data_fashion_mnist(32)\n",
    "# for X, y in train_iter:\n",
    "#     print(X.shape, X.dtype, y.shape, y.dtype)\n",
    "#     show_images(X, 2, 8, titles=get_fashion_mnist_labels(y))\n",
    "#     break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b87a721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.083"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "\n",
    "W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)\n",
    "b = torch.zeros(num_outputs, requires_grad=True)\n",
    "def softmax(X):\n",
    "    X_exp = torch.exp(X)\n",
    "    partition = X_exp.sum(1, keepdim=True)\n",
    "    return X_exp / partition  # 这里应用了广播机制\n",
    "X = torch.normal(0, 1, (2, 5))\n",
    "X_prob = softmax(X)\n",
    "X_prob, X_prob.sum(1,keepdim=True)\n",
    "def net(X):\n",
    "    return softmax(torch.matmul(X.reshape((-1, W.shape[0])), W) + b)\n",
    "y = torch.tensor([0, 2])\n",
    "y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])\n",
    "y_hat[[0, 1], y]\n",
    "class Accumulator:  #@save\n",
    "    \"\"\"在n个变量上累加\"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "def cross_entropy(y_hat, y):\n",
    "    return - torch.log(y_hat[range(len(y_hat)), y])\n",
    "\n",
    "cross_entropy(y_hat, y)\n",
    "def accuracy(y_hat, y):  #@save\n",
    "    \"\"\"计算预测正确的数量\"\"\"\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "\n",
    "    return (cmp.type(y.dtype).sum())\n",
    "accuracy(y_hat, y) / len(y)\n",
    "def evaluate_accuracy(net, data_iter):  #@save\n",
    "    \"\"\"计算在指定数据集上模型的精度\"\"\"\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval()  # 将模型设置为评估模式\n",
    "    metric = Accumulator(2)  # 正确预测数、预测总数\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            #print(\"Input shape:\", X.shape,y.shape)\n",
    "            metric.add(accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]\n",
    "evaluate_accuracy(net, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed72e61a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 144\u001b[39m\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m optim.SGD([W, b], lr, batch_size)\n\u001b[32m    143\u001b[39m num_epochs = \u001b[32m10\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m \u001b[43mtrain_ch3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdater\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 131\u001b[39m, in \u001b[36mtrain_ch3\u001b[39m\u001b[34m(net, train_iter, test_iter, loss, num_epochs, updater)\u001b[39m\n\u001b[32m    128\u001b[39m animator = Animator(xlabel=\u001b[33m'\u001b[39m\u001b[33mepoch\u001b[39m\u001b[33m'\u001b[39m, xlim=[\u001b[32m1\u001b[39m, num_epochs], ylim=[\u001b[32m0.3\u001b[39m, \u001b[32m0.9\u001b[39m],\n\u001b[32m    129\u001b[39m                     legend=[\u001b[33m'\u001b[39m\u001b[33mtrain loss\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtrain acc\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtest acc\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     train_metrics = \u001b[43mtrain_epoch_ch3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdater\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mepoch:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,train_metrics[\u001b[32m0\u001b[39m],train_metrics[\u001b[32m1\u001b[39m])\n\u001b[32m    133\u001b[39m     test_acc = evaluate_accuracy(net, test_iter)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 109\u001b[39m, in \u001b[36mtrain_epoch_ch3\u001b[39m\u001b[34m(net, train_iter, loss, updater)\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# 训练损失总和、训练准确度总和、样本数\u001b[39;00m\n\u001b[32m    108\u001b[39m metric = Accumulator(\u001b[32m3\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 计算梯度并更新参数\u001b[39;49;00m\n\u001b[32m    111\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m    \u001b[49m\u001b[43ml\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1491\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1490\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1491\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1494\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1453\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1449\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1450\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1451\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1452\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1453\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1454\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1455\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1284\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1271\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1272\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1273\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1281\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1282\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1283\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1284\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1285\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1286\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1287\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1288\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1289\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\queues.py:111\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[32m    110\u001b[39m     timeout = deadline - time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    112\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\connection.py:257\u001b[39m, in \u001b[36m_ConnectionBase.poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    255\u001b[39m \u001b[38;5;28mself\u001b[39m._check_closed()\n\u001b[32m    256\u001b[39m \u001b[38;5;28mself\u001b[39m._check_readable()\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\connection.py:346\u001b[39m, in \u001b[36mPipeConnection._poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m    344\u001b[39m             _winapi.PeekNamedPipe(\u001b[38;5;28mself\u001b[39m._handle)[\u001b[32m0\u001b[39m] != \u001b[32m0\u001b[39m):\n\u001b[32m    345\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\connection.py:1096\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(object_list, timeout)\u001b[39m\n\u001b[32m   1093\u001b[39m                 ready_objects.add(o)\n\u001b[32m   1094\u001b[39m                 timeout = \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1096\u001b[39m     ready_handles = \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1097\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1098\u001b[39m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[32m   1099\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\multiprocessing\\connection.py:1028\u001b[39m, in \u001b[36m_exhaustive_wait\u001b[39m\u001b[34m(handles, timeout)\u001b[39m\n\u001b[32m   1026\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[32m   1027\u001b[39m     short_L = L[:\u001b[32m60\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(L) > \u001b[32m60\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m L\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m     res = \u001b[43m_winapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mWaitForMultipleObjects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshort_L\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1029\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m res == WAIT_TIMEOUT:\n\u001b[32m   1030\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "batch_size=256\n",
    "class Animator:\n",
    "    \"\"\"动态绘制训练指标的实用类\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(6, 4)):\n",
    "        \"\"\"\n",
    "        参数说明：\n",
    "        - xlabel/ylabel: 坐标轴标签\n",
    "        - legend: 图例列表\n",
    "        - xlim/ylim: 坐标轴范围 (例如 (0, 10))\n",
    "        - xscale/yscale: 坐标轴缩放类型 ('linear'/'log')\n",
    "        - fmts: 线条样式列表 (对应不同指标)\n",
    "        - figsize: 图像尺寸\n",
    "        \"\"\"\n",
    "        # 初始化图形和坐标轴\n",
    "        \n",
    "        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows*ncols == 1:\n",
    "            self.axes = [self.axes]  # 统一处理单轴情况\n",
    "        \n",
    "        # 配置坐标轴参数\n",
    "        self.config = {\n",
    "            'xlabel': xlabel,\n",
    "            'ylabel': ylabel,\n",
    "            'legend': legend or [],\n",
    "            'xlim': xlim,\n",
    "            'ylim': ylim,\n",
    "            'xscale': xscale,\n",
    "            'yscale': yscale\n",
    "        }\n",
    "        \n",
    "        # 数据存储结构\n",
    "        self.X, self.Y = None, None\n",
    "        self.fmts = fmts\n",
    "        \n",
    "        # 设置SVG清晰显示\n",
    "        plt.rcParams['figure.figsize'] = figsize\n",
    "        plt.rcParams['svg.fonttype'] = 'none'  # 确保SVG文本可编辑\n",
    "\n",
    "    def _config_axes(self):\n",
    "        \"\"\"配置坐标轴属性\"\"\"\n",
    "        ax = self.axes[0]\n",
    "        if self.config['xlabel']:\n",
    "            ax.set_xlabel(self.config['xlabel'])\n",
    "        if self.config['ylabel']:\n",
    "            ax.set_ylabel(self.config['ylabel'])\n",
    "        if self.config['xlim']:\n",
    "            ax.set_xlim(self.config['xlim'])\n",
    "        if self.config['ylim']:\n",
    "            ax.set_ylim(self.config['ylim'])\n",
    "        ax.set_xscale(self.config['xscale'])\n",
    "        ax.set_yscale(self.config['yscale'])\n",
    "        if self.config['legend']:\n",
    "            ax.legend(self.config['legend'])\n",
    "        ax.grid(True)  # 添加网格线\n",
    "\n",
    "    def add(self, x, y):\n",
    "        \"\"\"\n",
    "        添加数据点：\n",
    "        - x: 横坐标值（标量或列表）\n",
    "        - y: 纵坐标值（标量或列表，对应不同指标）\n",
    "        \"\"\"\n",
    "        # 数据标准化处理\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "            \n",
    "        # 初始化数据存储\n",
    "        if self.X is None:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if self.Y is None:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "            \n",
    "        # 存储数据点\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "                \n",
    "        # 清空当前图形\n",
    "        self.axes[0].cla()\n",
    "        \n",
    "        # 重绘所有线条\n",
    "        for x_arr, y_arr, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x_arr, y_arr, fmt)\n",
    "            \n",
    "        # 应用坐标轴配置\n",
    "        self._config_axes()\n",
    "        \n",
    "        # Jupyter动态显示\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)\n",
    "        plt.close(self.fig)  # 防止重复显示静态图\n",
    "\n",
    "def train_epoch_ch3(net, train_iter, loss, updater):  #@save\n",
    "    \"\"\"训练模型一个迭代周期（定义见第3章）\"\"\"\n",
    "    # 将模型设置为训练模式\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.train()\n",
    "    # 训练损失总和、训练准确度总和、样本数\n",
    "    metric = Accumulator(3)\n",
    "    for X, y in train_iter:\n",
    "        # 计算梯度并更新参数\n",
    "        y_hat = net(X)\n",
    "\n",
    "        l = loss(y_hat, y)\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            # 使用PyTorch内置的优化器和损失函数\n",
    "            updater.zero_grad()\n",
    "            l.mean().backward()\n",
    "            updater.step()\n",
    "        else:\n",
    "            # 使用定制的优化器和损失函数\n",
    "            l.sum().backward()\n",
    "            updater(X.shape[0])\n",
    "        metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())\n",
    "    # 返回训练损失和训练精度\n",
    "    return metric[0] / metric[2], metric[1] / metric[2]\n",
    "def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):  #@save\n",
    "    \"\"\"训练模型（定义见第3章）\"\"\"\n",
    "    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9],\n",
    "                        legend=['train loss', 'train acc', 'test acc'])\n",
    "    for epoch in range(num_epochs):\n",
    "        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)\n",
    "        print(f\"epoch:{epoch}\",train_metrics[0],train_metrics[1])\n",
    "        test_acc = evaluate_accuracy(net, test_iter)\n",
    "        animator.add(epoch + 1, train_metrics + (test_acc,))\n",
    "    train_loss, train_acc = train_metrics\n",
    "    assert train_loss < 0.5, train_loss\n",
    "    assert train_acc <= 1 and train_acc > 0.7, train_acc\n",
    "    assert test_acc <= 1 and test_acc > 0.7, test_acc\n",
    "    \n",
    "lr = 0.1\n",
    "def updater(batch_size):\n",
    "    return optim.SGD([W, b], lr, batch_size)\n",
    "num_epochs = 10\n",
    "train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
