{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a44ba730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn as nn\n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "from torchvision import transforms as transforms\n",
    "def load_data_fashion_mnist(batch_size, resize=None):  #@save\n",
    "    \"\"\"下载Fashion-MNIST数据集，然后将其加载到内存中\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(\n",
    "        root=r\"C:\\Users\\Lenovo\\Desktop\\visiondata\", train=True, transform=trans, download=True)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(\n",
    "        root=r\"C:\\Users\\Lenovo\\Desktop\\visiondata\", train=False, transform=trans, download=True)\n",
    "    return (data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                            num_workers=12),\n",
    "            data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
    "                            num_workers=12))\n",
    "trans = transforms.ToTensor()\n",
    "mnist_train = torchvision.datasets.FashionMNIST(\n",
    "    root=r\"C:\\Users\\Lenovo\\Desktop\\visiondata\", train=True, transform=trans, download=True)\n",
    "mnist_test = torchvision.datasets.FashionMNIST(\n",
    "    root=r\"C:\\Users\\Lenovo\\Desktop\\visiondata\", train=False, transform=trans, download=True)\n",
    "batch_size = 256\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "604d8498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.type of Sequential(\n",
      "  (0): Flatten(start_dim=1, end_dim=-1)\n",
      "  (1): Linear(in_features=784, out_features=10, bias=True)\n",
      "  (2): Softmax(dim=1)\n",
      ")>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=10, bias=True)\n",
       "  (2): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyTorch不会隐式地调整输入的形状。因此，\n",
    "# 我们在线性层前定义了展平层（flatten），来调整网络输入的形状\n",
    "net = nn.Sequential(nn.Flatten(), \n",
    "                    nn.Linear(784, 10),\n",
    "                    nn.Softmax(dim=1))\n",
    "\n",
    "print(net.type)\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std=0.01)\n",
    "\n",
    "net.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdb10e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 0.5705235799153646 0.8333333333333334\n",
      "epoch:1 0.5167417526245117 0.8541666666666666\n",
      "epoch:2 0.4672144254048665 0.8541666666666666\n",
      "epoch:3 0.6250601609547933 0.7916666666666666\n",
      "epoch:4 0.46855608622233075 0.7708333333333334\n",
      "epoch:5 0.3572562138239543 0.8958333333333334\n",
      "epoch:6 0.3492439190546672 0.8958333333333334\n",
      "epoch:7 0.3567405144373576 0.8958333333333334\n",
      "epoch:8 0.5239689747492472 0.8125\n",
      "epoch:9 0.34664026896158856 0.875\n"
     ]
    }
   ],
   "source": [
    "def cross_entropy(y_hat, y):\n",
    "    return - torch.log(y_hat[range(len(y_hat)), y])\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "epochs=10\n",
    "def evaluate_accuracy(net, data_iter):  #@save\n",
    "    \"\"\"计算在指定数据集上模型的精度\"\"\"\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval()  # 将模型设置为评估模式\n",
    "    metric = Accumulator(2)  # 正确预测数、预测总数\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            #print(\"Input shape:\", X.shape,y.shape)\n",
    "            metric.add(accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]\n",
    "def accuracy(y_hat, y):  #@save\n",
    "    \"\"\"计算预测正确的数量\"\"\"\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "\n",
    "    return (cmp.type(y.dtype).sum())\n",
    "def train_epoch_ch3(net, train_iter, loss):  #@save\n",
    "    \"\"\"训练模型一个迭代周期（定义见第3章）\"\"\"\n",
    "    # 将模型设置为训练模式\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.train()\n",
    "    # 训练损失总和、训练准确度总和、样本数\n",
    "    metric = Accumulator(3)\n",
    "    updater=torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "    #X,y=next(iter(train_iter))\n",
    "    for X, y in train_iter:\n",
    "        # 计算梯度并更新参数\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y)\n",
    "        updater.zero_grad()\n",
    "        l.mean().backward()\n",
    "        updater.step()\n",
    "    # else:\n",
    "    #     # 使用定制的优化器和损失函数\n",
    "    #     l.sum().backward()\n",
    "    #     updater(X.shape[0])\n",
    "    metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())  # 返回训练损失和训练精度\n",
    "    return metric[0] / metric[2], metric[1] / metric[2]\n",
    "class Accumulator:  #@save\n",
    "    \"\"\"在n个变量上累加\"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "def train_ch3(net, train_iter, test_iter, loss, num_epochs):  #@save\n",
    "    \"\"\"训练模型（定义见第3章）\"\"\"\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_metrics = train_epoch_ch3(net, train_iter, loss)\n",
    "        print(f\"epoch:{epoch}\",train_metrics[0],train_metrics[1])\n",
    "        test_acc = evaluate_accuracy(net, test_iter)\n",
    "\n",
    "    train_loss, train_acc = train_metrics\n",
    "    assert train_loss < 0.5, train_loss\n",
    "    assert train_acc <= 1 and train_acc > 0.7, train_acc\n",
    "    assert test_acc <= 1 and test_acc > 0.7, test_acc\n",
    "num_epochs = 10\n",
    "train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec6f31bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y tensor([5, 0, 5, 0, 4, 6, 3, 2, 7, 8, 6, 2, 0, 9, 1, 1, 1, 7, 7, 0, 6, 1, 1, 9,\n",
      "        9, 7, 1, 8, 5, 1, 4, 2, 6, 3, 4, 0, 0, 9, 0, 5, 5, 4, 5, 1, 2, 3, 6, 2,\n",
      "        0, 7, 5, 1, 0, 5, 6, 1, 3, 9, 6, 3, 0, 4, 7, 9, 1, 7, 8, 7, 0, 7, 3, 9,\n",
      "        2, 2, 8, 7, 0, 8, 8, 9, 9, 9, 3, 6, 7, 5, 7, 9, 5, 8, 4, 8, 3, 8, 8, 6,\n",
      "        2, 0, 1, 1, 4, 0, 9, 7, 7, 2, 4, 3, 4, 4, 8, 3, 3, 9, 0, 9, 7, 2, 6, 2,\n",
      "        0, 6, 1, 7, 0, 0, 8, 1, 3, 9, 1, 5, 8, 2, 2, 6, 5, 5, 1, 8, 3, 1, 6, 0,\n",
      "        5, 2, 3, 9, 5, 4, 5, 8, 7, 2, 4, 5, 3, 1, 7, 4, 9, 7, 9, 6, 8, 7, 7, 2,\n",
      "        6, 4, 9, 4, 4, 1, 1, 0, 6, 5, 1, 7, 7, 7, 2, 0, 1, 0, 5, 0, 3, 1, 3, 5,\n",
      "        0, 8, 9, 9, 9, 4, 4, 0, 0, 2, 9, 2, 1, 5, 4, 1, 6, 0, 6, 2, 8, 2, 1, 4,\n",
      "        4, 2, 5, 1, 8, 0, 1, 9, 3, 3, 0, 4, 4, 2, 1, 7, 0, 8, 7, 4, 5, 8, 9, 1,\n",
      "        9, 7, 8, 6, 6, 0, 5, 5, 0, 9, 5, 4, 2, 1, 2, 2])\n",
      "y_hat tensor([[ -15.8006,  -14.5406,  -17.2908,  ...,   24.9627,  -22.8013,\n",
      "          -15.8308],\n",
      "        [ -84.4206,  -95.1518,  -81.7254,  ...,   56.2284,  -85.9615,\n",
      "          -67.2360],\n",
      "        [ -46.2516,  -30.8529,  -52.6396,  ...,   57.2858,  -64.9243,\n",
      "          -71.0223],\n",
      "        ...,\n",
      "        [ -30.7616,  -44.1983,  -25.8884,  ...,   16.4261,  -21.9810,\n",
      "          -18.9447],\n",
      "        [-102.9139,  -93.5421, -111.8551,  ...,   69.1799, -103.2317,\n",
      "          -82.7277],\n",
      "        [ -86.5843,  -87.6512,  -86.7807,  ...,   57.6377,  -84.1967,\n",
      "          -67.7805]], grad_fn=<AddmmBackward0>) 256\n",
      "tensor(nan, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x,y=next(iter(train_iter))\n",
    "y_hat=net(x)\n",
    "print(\"y\",y)\n",
    "print(\"y_hat\",y_hat,len(y_hat))\n",
    "loss=cross_entropy(y_hat,y)\n",
    "print(loss.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5d4bc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([5, 1, 4, 7, 6, 9, 4, 4, 1, 2, 1, 7, 1, 3, 0, 9, 6, 8, 1, 0, 7, 8, 6, 9,\n",
    "        3, 0, 5, 1, 4, 0, 9, 7, 3, 4, 6, 8, 6, 1, 6, 3, 5, 6, 9, 3, 6, 5, 8, 2,\n",
    "        2, 3, 6, 0, 0, 4, 0, 8, 1, 0, 3, 1, 1, 3, 7, 6, 1, 3, 3, 8, 0, 9, 4, 4,\n",
    "        7, 7, 1, 7, 7, 2, 2, 1, 0, 3, 1, 0, 9, 5, 0, 5, 1, 8, 8, 5, 7, 7, 5, 7,\n",
    "        5, 2, 8, 7, 7, 2, 7, 8, 2, 0, 0, 6, 3, 7, 7, 3, 0, 4, 0, 8, 1, 6, 2, 9,\n",
    "        8, 5, 5, 1, 4, 5, 3, 2, 7, 7, 0, 4, 9, 2, 4, 0, 1, 3, 2, 2, 8, 8, 6, 9,\n",
    "        5, 9, 1, 4, 1, 7, 7, 4, 4, 3, 5, 4, 5, 5, 6, 4, 7, 4, 1, 0, 3, 6, 2, 8,\n",
    "        2, 4, 7, 8, 4, 4, 8, 4, 3, 5, 0, 7, 0, 1, 6, 1, 9, 3, 9, 6, 1, 2, 8, 5,\n",
    "        3, 5, 1, 2, 3, 0, 9, 7, 9, 7, 5, 4, 3, 0, 5, 0, 6, 1, 1, 2, 7, 9, 4, 9,\n",
    "        2, 9, 2, 6, 5, 0, 0, 3, 5, 8, 2, 2, 2, 0, 3, 3, 5, 8, 8, 7, 2, 0, 8, 6,\n",
    "        8, 3, 0, 6, 1, 4, 6, 6, 9, 8, 9, 5, 5, 0, 3, 6])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
