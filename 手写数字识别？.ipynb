{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ba45b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),\n",
    "    nn.Linear(120, 84), nn.Sigmoid(),\n",
    "    nn.Linear(84, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d866e1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape: \t torch.Size([1, 6, 28, 28])\n",
      "Sigmoid output shape: \t torch.Size([1, 6, 28, 28])\n",
      "AvgPool2d output shape: \t torch.Size([1, 6, 14, 14])\n",
      "Conv2d output shape: \t torch.Size([1, 16, 10, 10])\n",
      "Sigmoid output shape: \t torch.Size([1, 16, 10, 10])\n",
      "AvgPool2d output shape: \t torch.Size([1, 16, 5, 5])\n",
      "Flatten output shape: \t torch.Size([1, 400])\n",
      "Linear output shape: \t torch.Size([1, 120])\n",
      "Sigmoid output shape: \t torch.Size([1, 120])\n",
      "Linear output shape: \t torch.Size([1, 84])\n",
      "Sigmoid output shape: \t torch.Size([1, 84])\n",
      "Linear output shape: \t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(size=(1, 1, 28, 28), dtype=torch.float32)\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape: \\t',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b647d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "def load_data_fashion_mnist(batch_size, resize=None):  #@save\n",
    "    \"\"\"下载Fashion-MNIST数据集，然后将其加载到内存中\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(\n",
    "        root=r\"C:\\Users\\Lenovo\\Desktop\\visiondata\", train=True, transform=trans, download=True)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(\n",
    "        root=r\"C:\\Users\\Lenovo\\Desktop\\visiondata\", train=False, transform=trans, download=True)\n",
    "    return (data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                            num_workers=12),\n",
    "            data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
    "                            num_workers=12))\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71f5bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accumulator:  #@save\n",
    "    \"\"\"在n个变量上累加\"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "def accuracy(y_hat, y):  #@save\n",
    "    \"\"\"计算预测正确的数量\"\"\"\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "\n",
    "    return (cmp.type(y.dtype).sum())\n",
    "def evaluate_accuracy_gpu(net, data_iter, device=None): #@save\n",
    "    \"\"\"使用GPU计算模型在数据集上的精度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval()  # 设置为评估模式\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    # 正确预测的数量，总预测的数量\n",
    "    metric = Accumulator(2)\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                # BERT微调所需的（之后将介绍）\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            metric.add(accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77205956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_gpu(i=0):  #@save\n",
    "    \"\"\"如果存在，则返回gpu(i)，否则返回cpu()\"\"\"\n",
    "    if torch.cuda.device_count() >= i + 1:\n",
    "        return torch.device(f'cuda:{i}')\n",
    "    return torch.device('cpu')\n",
    "#@save\n",
    "import time\n",
    "def train_ch6(net, train_iter, test_iter, num_epochs, lr, device):\n",
    "    \"\"\"用GPU训练模型(在第六章定义)\"\"\"\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    timer, num_batches = time.time(), len(train_iter)\n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练损失之和，训练准确率之和，样本数\n",
    "        metric = Accumulator(3)\n",
    "        net.train()\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "          \n",
    "            optimizer.zero_grad()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l * X.shape[0], accuracy(y_hat, y), X.shape[0])\n",
    "            \n",
    "            train_l = metric[0] / metric[2]\n",
    "            train_acc = metric[1] / metric[2]\n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                print(f\"epoch{epoch}: loss{train_l},acc{train_acc}\")\n",
    "        test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
    "        print(f\"epoch{epoch}: testacc{test_acc}\")\n",
    "    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '\n",
    "          f'test acc {test_acc:.3f}')\n",
    "    print(f'{metric[2] * num_epochs / (time.time()-timer)} examples/sec '\n",
    "          f'on {str(device)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2025822d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cpu\n",
      "epoch0: loss2.361312911865559,acc0.10330784574468085\n",
      "epoch0: loss2.3375485831118645,acc0.10206117021276596\n",
      "epoch0: loss2.329039544923931,acc0.10064827127659574\n",
      "epoch0: loss2.323611130105688,acc0.10081449468085106\n",
      "epoch0: loss2.3199821680704753,acc0.10208333333333333\n",
      "epoch0: testacc0.1\n",
      "epoch1: loss2.303870774329977,acc0.09674202127659574\n",
      "epoch1: loss2.3004840967503,acc0.10679853723404255\n",
      "epoch1: loss2.2697279385641114,acc0.1322307180851064\n",
      "epoch1: loss2.0846475318391273,acc0.19971742021276595\n",
      "epoch1: loss1.9177910769144695,acc0.25716666666666665\n",
      "epoch1: testacc0.4818\n",
      "epoch2: loss1.0853477919355352,acc0.562749335106383\n",
      "epoch2: loss1.0310274165995577,acc0.5893035239361702\n",
      "epoch2: loss1.0023803478437112,acc0.6015625\n",
      "epoch2: loss0.9725602082115539,acc0.6136136968085106\n",
      "epoch2: loss0.94049265721639,acc0.6276333333333334\n",
      "epoch2: testacc0.6375\n",
      "epoch3: loss0.8117330429401803,acc0.6802692819148937\n",
      "epoch3: loss0.7751781566345946,acc0.6914893617021277\n",
      "epoch3: loss0.7649399819948994,acc0.6989971187943262\n",
      "epoch3: loss0.7497634548456111,acc0.704600232712766\n",
      "epoch3: loss0.740176768175761,acc0.7079166666666666\n",
      "epoch3: testacc0.7059\n",
      "epoch4: loss0.6906931527117466,acc0.7244847074468085\n",
      "epoch4: loss0.6708488083900289,acc0.7349567819148937\n",
      "epoch4: loss0.657244954971557,acc0.742436835106383\n",
      "epoch4: loss0.6561436237806969,acc0.7431017287234043\n",
      "epoch4: loss0.6493006052652994,acc0.7458166666666667\n",
      "epoch4: testacc0.7571\n",
      "epoch5: loss0.6171942898567687,acc0.7639627659574468\n",
      "epoch5: loss0.6048551227184052,acc0.7663314494680851\n",
      "epoch5: loss0.6062653206341656,acc0.7661513741134752\n",
      "epoch5: loss0.6022002727110335,acc0.7678482380319149\n",
      "epoch5: loss0.5960399516423543,acc0.7689\n",
      "epoch5: testacc0.7747\n",
      "epoch6: loss0.5676605828264927,acc0.7811668882978723\n",
      "epoch6: loss0.5651809205400183,acc0.7820395611702128\n",
      "epoch6: loss0.5618346270094526,acc0.7829399379432624\n",
      "epoch6: loss0.5555982125249315,acc0.7856133643617021\n",
      "epoch6: loss0.5545477177937825,acc0.7861833333333333\n",
      "epoch6: testacc0.7484\n",
      "epoch7: loss0.5283631638009497,acc0.8021110372340425\n",
      "epoch7: loss0.5223420582553173,acc0.8011552526595744\n",
      "epoch7: loss0.5175414618025435,acc0.8032191932624113\n",
      "epoch7: loss0.5174572226849008,acc0.8033369348404256\n",
      "epoch7: loss0.5177065260569255,acc0.8033833333333333\n",
      "epoch7: testacc0.7902\n",
      "epoch8: loss0.49652724507007195,acc0.8129155585106383\n",
      "epoch8: loss0.4932011102742337,acc0.8137466755319149\n",
      "epoch8: loss0.492161011653589,acc0.8143007535460993\n",
      "epoch8: loss0.49605625693468336,acc0.8126662234042553\n",
      "epoch8: loss0.495206751759847,acc0.8135833333333333\n",
      "epoch8: testacc0.7797\n",
      "epoch9: loss0.4856475052681375,acc0.8146609042553191\n",
      "epoch9: loss0.48318782797519194,acc0.8179853723404256\n",
      "epoch9: loss0.47682488936904477,acc0.8210050975177305\n",
      "epoch9: loss0.47301658528282287,acc0.8213306183510638\n",
      "epoch9: loss0.47258955961863197,acc0.8213666666666667\n",
      "epoch9: testacc0.8109\n",
      "loss 0.473, train acc 0.821, test acc 0.811\n",
      "1287.2259436084826 examples/sec on cpu\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.9, 10\n",
    "#train_ch6(net, train_iter, test_iter, num_epochs, lr,try_gpu())\n",
    "train_ch6(net, train_iter, test_iter, num_epochs, lr,torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77df0163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 13 19:36:36 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 576.28                 Driver Version: 576.28         CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1650      WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   65C    P0             17W /   50W |    1156MiB /   4096MiB |     14%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            5672    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A            6496    C+G   ...re\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A            9308    C+G   ...e Experience\\NVIDIA Share.exe      N/A      |\n",
      "|    0   N/A  N/A           10516    C+G   ...h_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A           11668      C   ...s\\Python\\Python313\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           12148    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A           12408    C+G   ...e Experience\\NVIDIA Share.exe      N/A      |\n",
      "|    0   N/A  N/A           13924    C+G   ...acted\\runtime\\WeChatAppEx.exe      N/A      |\n",
      "|    0   N/A  N/A           15200    C+G   ...PotPlayer\\PotPlayerMini64.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a1e567e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n",
      "True\n",
      "12.4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__) # 查看torch版本\n",
    "print(torch.cuda.is_available()) # 看安装好的torch和cuda能不能用，也就是看GPU能不能用\n",
    "\n",
    "print(torch.version.cuda) # 输出一个 cuda 版本，注意：上述输出的 cuda 的版本并不一定是 Pytorch 在实际系统上运行时使用的 cuda 版本，而是编译该 Pytorch release 版本时使用的 cuda 版本，详见：https://blog.csdn.net/xiqi4145/article/details/110254093\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9adbc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
