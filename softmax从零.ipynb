{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d6ade37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "# 通过ToTensor实例将图像数据从PIL类型变换成32位浮点数格式，\n",
    "# 并除以255使得所有像素的数值均在0～1之间\n",
    "trans = transforms.ToTensor()\n",
    "mnist_train = torchvision.datasets.FashionMNIST(\n",
    "    root=r\"C:\\Users\\Lenovo\\Desktop\\visiondata\", train=True, transform=trans, download=True)\n",
    "mnist_test = torchvision.datasets.FashionMNIST(\n",
    "    root=r\"C:\\Users\\Lenovo\\Desktop\\visiondata\", train=False, transform=trans, download=True)\n",
    "len(mnist_train), len(mnist_test)\n",
    "type(mnist_train[1])#60000行，2列，第一列是图像ternsor 1,28,28，第二列是label(int)\n",
    "def get_fashion_mnist_labels(labels):  #@save\n",
    "    \"\"\"返回Fashion-MNIST数据集的文本标签\"\"\"\n",
    "    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "    return [text_labels[int(i)] for i in labels]\n",
    "def show_images(imgs, num_rows, num_cols, titles=None, scale=1):  #@save\n",
    "    \"\"\"绘制图像列表\"\"\"\n",
    "    figsize = (num_cols * scale, num_rows * scale)\n",
    "    _, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    for i, (ax, img) in enumerate(zip(axes, imgs)):\n",
    "        if torch.is_tensor(img):\n",
    "            # 图片张量\n",
    "            #print(img.squeeze().numpy())\n",
    "            ax.imshow(img.squeeze().numpy())\n",
    "        else:\n",
    "            # PIL图片\n",
    "            ax.imshow(img)\n",
    "        \n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "        if titles:\n",
    "            ax.set_title(titles[i])\n",
    "        #ax.axis('off')\n",
    "    return axes\n",
    "# X, y = next(iter(data.DataLoader(mnist_train, batch_size=18)))\n",
    "# show_images(X.reshape(18, 28, 28), 2, 9, titles=get_fashion_mnist_labels(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63175648",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter = data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                             num_workers=12)\n",
    "def load_data_fashion_mnist(batch_size, resize=None):  #@save\n",
    "    \"\"\"下载Fashion-MNIST数据集，然后将其加载到内存中\"\"\"\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0, transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(\n",
    "        root=r\"C:\\Users\\Lenovo\\Desktop\\visiondata\", train=True, transform=trans, download=True)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(\n",
    "        root=r\"C:\\Users\\Lenovo\\Desktop\\visiondata\", train=False, transform=trans, download=True)\n",
    "    return (data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
    "                            num_workers=12),\n",
    "            data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
    "                            num_workers=12))\n",
    "train_iter, test_iter = load_data_fashion_mnist(32)\n",
    "# for X, y in train_iter:\n",
    "#     print(X.shape, X.dtype, y.shape, y.dtype)\n",
    "#     show_images(X, 2, 8, titles=get_fashion_mnist_labels(y))\n",
    "#     break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcdbb976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0526"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "\n",
    "W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)\n",
    "b = torch.zeros(num_outputs, requires_grad=True)\n",
    "def softmax(X):\n",
    "    X_exp = torch.exp(X)\n",
    "    partition = X_exp.sum(1, keepdim=True)\n",
    "    return X_exp / partition  # 这里应用了广播机制\n",
    "X = torch.normal(0, 1, (2, 5))\n",
    "X_prob = softmax(X)\n",
    "X_prob, X_prob.sum(1,keepdim=True)\n",
    "def net(X):\n",
    "    return softmax(torch.matmul(X.reshape((-1, W.shape[0])), W) + b)\n",
    "y = torch.tensor([0, 2])\n",
    "y_hat = torch.tensor([[0.1, 0.3, 0.6], [0.3, 0.2, 0.5]])\n",
    "y_hat[[0, 1], y]\n",
    "class Accumulator:  #@save\n",
    "    \"\"\"在n个变量上累加\"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.data = [0.0] * n\n",
    "\n",
    "    def add(self, *args):\n",
    "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = [0.0] * len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "def cross_entropy(y_hat, y):\n",
    "    return - torch.log(y_hat[range(len(y_hat)), y])\n",
    "\n",
    "cross_entropy(y_hat, y)\n",
    "def accuracy(y_hat, y):  #@save\n",
    "    \"\"\"计算预测正确的数量\"\"\"\n",
    "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "\n",
    "    return (cmp.type(y.dtype).sum())\n",
    "accuracy(y_hat, y) / len(y)\n",
    "def evaluate_accuracy(net, data_iter):  #@save\n",
    "    \"\"\"计算在指定数据集上模型的精度\"\"\"\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.eval()  # 将模型设置为评估模式\n",
    "    metric = Accumulator(2)  # 正确预测数、预测总数\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            #print(\"Input shape:\", X.shape,y.shape)\n",
    "            metric.add(accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]\n",
    "evaluate_accuracy(net, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10272cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 nan 0.03125\n",
      "epoch:1 nan 0.09375\n",
      "epoch:2 nan 0.03125\n",
      "epoch:3 nan 0.1875\n",
      "epoch:4 nan 0.09375\n",
      "epoch:5 nan 0.125\n",
      "epoch:6 nan 0.21875\n",
      "epoch:7 nan 0.03125\n",
      "epoch:8 nan 0.15625\n",
      "epoch:9 nan 0.125\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "nan",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     41\u001b[39m lr = \u001b[32m0.1\u001b[39m\n\u001b[32m     42\u001b[39m num_epochs = \u001b[32m10\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[43mtrain_ch3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mtrain_ch3\u001b[39m\u001b[34m(net, train_iter, test_iter, loss, num_epochs)\u001b[39m\n\u001b[32m     34\u001b[39m     test_acc = evaluate_accuracy(net, test_iter)\n\u001b[32m     36\u001b[39m train_loss, train_acc = train_metrics\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m train_loss < \u001b[32m0.5\u001b[39m, train_loss\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m train_acc <= \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m train_acc > \u001b[32m0.7\u001b[39m, train_acc\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m test_acc <= \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m test_acc > \u001b[32m0.7\u001b[39m, test_acc\n",
      "\u001b[31mAssertionError\u001b[39m: nan"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "batch_size=256\n",
    "def train_epoch_ch3(net, train_iter, loss):  #@save\n",
    "    \"\"\"训练模型一个迭代周期（定义见第3章）\"\"\"\n",
    "    # 将模型设置为训练模式\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.train()\n",
    "    # 训练损失总和、训练准确度总和、样本数\n",
    "    metric = Accumulator(3)\n",
    "    updater=optim.SGD([W, b], lr, batch_size)\n",
    "    #X,y=next(iter(train_iter))\n",
    "    for X, y in train_iter:\n",
    "        # 计算梯度并更新参数\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y)\n",
    "        updater.zero_grad()\n",
    "        l.mean().backward()\n",
    "        updater.step()\n",
    "    # else:\n",
    "    #     # 使用定制的优化器和损失函数\n",
    "    #     l.sum().backward()\n",
    "    #     updater(X.shape[0])\n",
    "    metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())\n",
    "    # 返回训练损失和训练精度\n",
    "    return metric[0] / metric[2], metric[1] / metric[2]\n",
    "def train_ch3(net, train_iter, test_iter, loss, num_epochs):  #@save\n",
    "    \"\"\"训练模型（定义见第3章）\"\"\"\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_metrics = train_epoch_ch3(net, train_iter, loss)\n",
    "        print(f\"epoch:{epoch}\",train_metrics[0],train_metrics[1])\n",
    "        test_acc = evaluate_accuracy(net, test_iter)\n",
    "\n",
    "    train_loss, train_acc = train_metrics\n",
    "    assert train_loss < 0.5, train_loss\n",
    "    assert train_acc <= 1 and train_acc > 0.7, train_acc\n",
    "    assert test_acc <= 1 and test_acc > 0.7, test_acc\n",
    "    \n",
    "lr = 0.1\n",
    "num_epochs = 10\n",
    "train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
