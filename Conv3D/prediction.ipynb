{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d39d6516-c389-4626-9736-8f47af21b35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "from functions import *\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36e5389b-e914-44c4-a596-c1494a39c007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN3D model reloaded!\n",
      "Predicting all 13320 videos:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 444/444 [03:21<00:00,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video prediction finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# set path\n",
    "#data_path = \"./jpegs_256/\"    # define UCF-101 spatial data path\n",
    "data_path = \"../temp/jpegs_256/\"\n",
    "action_name_path = './UCF101actions.pkl'\n",
    "save_model_path = \"./Conv3D_ckpt/\"\n",
    "\n",
    "# 3D CNN parameters\n",
    "fc_hidden1, fc_hidden2 = 256, 256\n",
    "dropout = 0.0        # dropout probability\n",
    "\n",
    "# training parameters\n",
    "k = 101            # number of target category\n",
    "batch_size = 30\n",
    "img_x, img_y = 256, 342  # resize video 2d frame size\n",
    "\n",
    "# Select which frame to begin & end in videos\n",
    "begin_frame, end_frame, skip_frame = 1, 29, 1\n",
    "\n",
    "\n",
    "with open(action_name_path, 'rb') as f:\n",
    "    action_names = pickle.load(f)   # load UCF101 actions names\n",
    "\n",
    "# convert labels -> category\n",
    "le = LabelEncoder()\n",
    "le.fit(action_names)\n",
    "\n",
    "# show how many classes there are\n",
    "list(le.classes_)\n",
    "\n",
    "# convert category -> 1-hot\n",
    "action_category = le.transform(action_names).reshape(-1, 1)\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(action_category)\n",
    "\n",
    "# # example\n",
    "# y = ['HorseRace', 'YoYo', 'WalkingWithDog']\n",
    "# y_onehot = labels2onehot(enc, le, y)\n",
    "# y2 = onehot2labels(le, y_onehot)\n",
    "\n",
    "actions = []\n",
    "fnames = os.listdir(data_path)\n",
    "\n",
    "all_names = []\n",
    "for f in fnames:\n",
    "    loc1 = f.find('v_')\n",
    "    loc2 = f.find('_g')\n",
    "    actions.append(f[(loc1 + 2): loc2])\n",
    "\n",
    "    all_names.append(f)\n",
    "\n",
    "\n",
    "# list all data files\n",
    "all_X_list = all_names              # all video file names\n",
    "all_y_list = labels2cat(le, actions)    # all video labels\n",
    "\n",
    "# data loading parameters\n",
    "use_cuda = torch.cuda.is_available()                   # check if GPU exists\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")   # use CPU or GPU\n",
    "params = {'batch_size': batch_size, 'shuffle': True, 'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "# image transformation\n",
    "transform = transforms.Compose([transforms.Resize([img_x, img_y]),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.5], std=[0.5])])\n",
    "\n",
    "selected_frames = np.arange(begin_frame, end_frame, skip_frame).tolist()\n",
    "\n",
    "# reset data loader\n",
    "all_data_params = {'batch_size': batch_size, 'shuffle': False, 'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "all_data_loader = data.DataLoader(Dataset_3DCNN(data_path, all_X_list, all_y_list, selected_frames, transform=transform), **all_data_params)\n",
    "\n",
    "\n",
    "# reload CRNN model\n",
    "cnn3d = CNN3D(t_dim=len(selected_frames), img_x=img_x, img_y=img_y,\n",
    "              drop_p=dropout, fc_hidden1=fc_hidden1,  fc_hidden2=fc_hidden2, num_classes=k).to(device)\n",
    "\n",
    "# Parallelize model to multiple GPUs\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    cnn3d = nn.DataParallel(cnn3d)\n",
    "\n",
    "cnn3d.load_state_dict(torch.load(os.path.join(save_model_path, '3dcnn_epoch14.pth')))\n",
    "print('CNN3D model reloaded!')\n",
    "\n",
    "\n",
    "# make all video predictions by reloaded model\n",
    "print('Predicting all {} videos:'.format(len(all_data_loader.dataset)))\n",
    "all_y_pred = Conv3d_final_prediction(cnn3d, device, all_data_loader) # Conv3d_final_prediction为functions.py自定义函数\n",
    "\n",
    "\n",
    "# write in pandas dataframe\n",
    "df = pd.DataFrame(data={'filename': fnames, 'y': cat2labels(le, all_y_list), 'y_pred': cat2labels(le, all_y_pred)})\n",
    "df.to_pickle(\"./UCF101_videos_prediction.pkl\")  # save pandas dataframe\n",
    "# pd.read_pickle(\"./all_videos_prediction.pkl\")\n",
    "print('video prediction finished!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
